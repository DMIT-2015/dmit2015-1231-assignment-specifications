= DMIT2015 Assignment 8 - Batch Processing
:source-highlighter: rouge
:max-width: 90%

== OBJECTIVE
Upon completion of this assignment, you will have demonstrated the ability to:

- Create a batch job with a batchlet step to download a CSV file 
- Create a batch job with a chunk step to extract data from a CSV file, transform a CSV line to a Java entity object, and persist the Java entity object to a database.
- Use a Geospatial database function to determine the distance between two points

== PROBLEM DESCRIPTION
You have been asked to setup the backend of an application with REST API endpoints to query data provided by the City of Edmonton on https://data.edmonton.ca/City-Administration/Property-Assessment-Data-Current-Calendar-Year-/q7d6-ambg[property assessment data for the current calendar year].
The dataset contains over 400K records that processing the data from CSV file directly using the Java Stream API would lead to high CPU usage and high memory usage.
To resolve the issue with high CPU usage and high memory usage you will import the data from the csv file to a database for processing by completing the following tasks:

. Write a Batch Job with a Batchlet step to download the CSV file from the City of Edmonton's Open Data Portal
. Write a Batch Job with a Chunk step to import the data from the downloaded CSV to database that supports GeoSpatial data such as SQL Server and Oracle. 
. Create REST API endpoints to query data on the imported database table for Edmonton Property Assessment Data.
. Create a Jakarta Faces page that can be used to start a batch job and to check its status.
. Create a Jakarta Faces page that can be used to test ONE of three queries.

=== Docker Containers for SQL Server and Oracle Database 23c
On your VM there are docker containers for SQL Server and Oracle Database 23c which must be manually started when you need to use them.
The following commands can be used to manage the Docker containers.
. To show all running docker containers
[source, console]
----
docker ps
----
. To show docker containers
[source, console]
----
docker ps --all
----
. To start the stopped docker container for SQL Server
[source, console]
----
docker start dmit2015-sqlserver
----
. To stop the running docker container for SQL Server
[source, console]
----
docker stop dmit2015-sqlserver
----

=== Docker Container for MariaDB
If you are planning to deploy your app to your OpenShift Developer Sandbox then it is recommended that you use MariaDB database.
To use MariaDB database in your VM, type the following commands one at a time:
[source, console]
----
docker pull mariadb

docker run --detach --name dmit2015-mariadb -p 3306:3306 --env MARIADB_USER=user2015 --env MARIADB_PASSWORD=Password2015 --env MARIADB_ROOT_PASSWORD=Password2015  mariadb:latest

docker exec -it dmit2015-mariadb bash

mariadb -h localhost -pPassword2015
create database DMIT2015CourseDB;
CREATE USER user2015@localhost IDENTIFIED BY 'Password2015';
GRANT ALL ON DMIT2015CourseDB.* TO 'user2015'@'%';
flush privileges;
quit

exit
----


== GIT REPOSITORY SETUP
. Login to Moodle and navigate to the link to create a private github repository for this assignment.
. Click on *Accept this assignment* to allow github to create a private github repository for you.
. Wait for the *You are ready to go!* messaage then click on the link to navigate to your assignment repository
. Click on *Clone or download* button then copy the URL to your repository to the clipboard.
. You can now import the git repository to the *~/git* folder from IntelliJ IDEA or from a Terminal window.

== PROJECT SETUP
. Open IntelliJ IDEA and create a new project using the *Jakarta EE* module and change following settings:
 .. Name: `dmit2015-assignment08-yourname`
 .. Location: `~/IdeaProjects/yourAssignment08GithubRepo`
 .. Template: `REST Service`
 .. Application server: `<No appliation server>` 
 .. Group: `dmit2015`
 .. Artifact: `assignment08-yourname`
 .. Check Next.
. On the Dependencies dialog, change the Version to *Jakarta EE 10* the select the following specifications:
 .. Web Profile (10.0.0)
 .. Batch (2.1.1)
. Click *Create*
. Make the following changes to `pom.xml`
* Change the element value for both `maven.compiler.target` and `maven.compiler.target` to `*17*`.
* Change the element value for `junit.version` to `*5.10.0*`.
* *Add* the following dependencies to the `<dependencies>` element.

poml.xml
[source, xml]
----
<dependency>
    <groupId>org.eclipse.microprofile</groupId>
    <artifactId>microprofile</artifactId>
    <version>6.0</version>
    <type>pom</type>
    <scope>provided</scope>
</dependency>

<dependency>
    <groupId>org.projectlombok</groupId>
    <artifactId>lombok</artifactId>
    <version>1.18.30</version>
    <scope>provided</scope>
</dependency>

<dependency>
    <groupId>jakarta.batch</groupId>
    <artifactId>jakarta.batch-api</artifactId>
    <version>2.1.1</version>
</dependency>

<dependency>
    <groupId>org.hibernate.orm</groupId>
    <artifactId>hibernate-core</artifactId>
    <version>6.3.1.Final</version>
</dependency>
<dependency>
    <groupId>org.hibernate.orm</groupId>
    <artifactId>hibernate-spatial</artifactId>
    <version>6.3.1.Final</version>
</dependency>

<dependency>
    <groupId>com.microsoft.sqlserver</groupId>
    <artifactId>mssql-jdbc</artifactId>
    <version>12.4.2.jre11</version>
</dependency>

<dependency>
    <groupId>com.oracle.database.jdbc</groupId>
    <artifactId>ojdbc11</artifactId>
    <version>23.2.0.0</version>
</dependency>

<dependency>
    <groupId>org.mariadb.jdbc</groupId>
    <artifactId>mariadb-java-client</artifactId>
    <version>3.2.0</version>
</dependency>

<!-- For IntelliJ IDEA Code Completion to detect project is using Jakarta Faces -->
<dependency>
    <groupId>jakarta.faces</groupId>
    <artifactId>jakarta.faces-api</artifactId>
    <version>4.0.1</version>
    <scope>provided</scope>
</dependency>

<dependency>
    <groupId>org.primefaces</groupId>
    <artifactId>primefaces</artifactId>
    <version>13.0.3</version>
    <classifier>jakarta</classifier>
</dependency>
<dependency>
    <groupId>org.webjars.npm</groupId>
    <artifactId>primeflex</artifactId>
    <version>3.3.1</version>
</dependency>
<dependency>
    <groupId>org.omnifaces</groupId>
    <artifactId>omnifaces</artifactId>
    <version>4.3</version>
</dependency>


<dependency>
    <groupId>org.junit.jupiter</groupId>
    <artifactId>junit-jupiter-params</artifactId>
    <version>${junit.version}</version>
    <scope>test</scope>
</dependency>

 <!-- AssertJ is for unit testing with Fluent Assertions -->
<dependency>
    <groupId>org.assertj</groupId>
    <artifactId>assertj-core</artifactId>
    <version>3.24.2</version>
    <scope>test</scope>
</dependency>

----

* Add the following dependencies to the `<plugins>` element.

poml.xml
[source, xml]
----
<!-- Plugin to build a bootable JAR for WildFly -->
<plugin>
    <!-- https://docs.wildfly.org/bootablejar/#wildfly_jar_dev_mode -->
    <!-- mvn wildfly-jar:dev-watch -->
    <groupId>org.wildfly.plugins</groupId>
    <artifactId>wildfly-jar-maven-plugin</artifactId>
    <version>10.0.0.Final</version>
    <configuration>
        <feature-pack-location>wildfly@maven(org.jboss.universe:community-universe)#29.0.1.Final</feature-pack-location>
        <layers>
            <!-- https://docs.wildfly.org/29/Bootable_Guide.html#wildfly_layers -->
            <layer>jaxrs-server</layer>
            <layer>microprofile-config</layer>
            <layer>batch-jberet</layer>
            <layer>jsf</layer>
            <layer>microprofile-rest-client</layer>
        </layers>
        <excluded-layers>
            <layer>deployment-scanner</layer>
        </excluded-layers>
        <plugin-options>
            <jboss-fork-embedded>true</jboss-fork-embedded>
        </plugin-options>
        <!-- https://docs.wildfly.org/bootablejar/#wildfly_jar_enabling_debug -->
        <jvmArguments>
            <!-- https://www.jetbrains.com/help/idea/attaching-to-local-process.html#attach-to-local -->
            <!-- To attach a debugger to the running server from IntelliJ IDEA
                1. From the main menu, choose `Run | Attach to Process`
                2. IntelliJ IDEA will show the list of running local processes. Select the process with the `xxx-bootable.jar` name to attach to.
            -->
            <arg>-agentlib:jdwp=transport=dt_socket,address=8787,server=y,suspend=n</arg>
        </jvmArguments>
        <timeout>360</timeout>

        <!-- Build a bootable JAR for cloud environment. -->
        <cloud />
    </configuration>
    <executions>
        <execution>
            <goals>
                <goal>package</goal>
            </goals>
        </execution>
    </executions>
</plugin>

----

[start=5]
 . Create the following Java packages in your project:
    .. `common.batch`
    .. `common.config`  
    .. `common.jpa`  
    .. `common.validator`  
    .. `dmit2015.batch` 
    .. `dmit2015.entity` 
    .. `dmit2015.repository` 
    .. `dmit2015.resource`

. In the `common.config` Java package, create the following *ApplicationConfig* class.

ApplicationConfig.java
[source, java]
----
package common.config;

import jakarta.annotation.sql.DataSourceDefinition;
import jakarta.annotation.sql.DataSourceDefinitions;
import jakarta.enterprise.context.ApplicationScoped;

@DataSourceDefinitions({
	
	@DataSourceDefinition(
		name="java:app/datasources/mssqlDS",
		className="com.microsoft.sqlserver.jdbc.SQLServerDataSource",
		url="jdbc:sqlserver://localhost;databaseName=DMIT2015CourseCourseDB;TrustServerCertificate=true",
		user="user2015",
		password="Password2015"),

	// @DataSourceDefinition(
	// 	name="java:app/datasources/oracleUser2015DS",
	// 	className="oracle.jdbc.xa.client.OracleXADataSource",
	// 	url="jdbc:oracle:thin:@localhost:1521/FREEPDB1",
	// 	user="user2015",
	// 	password="Password2015"),

    // @DataSourceDefinition(
	// 	name="java:app/datasources/mariadbDS",
	// 	className="org.mariadb.jdbc.MariaDbDataSource",
	// 	url="jdbc:mariadb://127.0.0.1:3306/DMIT2015CourseDB",
	// 	user="user2015",
	// 	password="Password2015"),

})

@ApplicationScoped
public class ApplicationConfig {

}
----

[start=7]
. Open the Jakarta Persistence configuration file *persistence.xml* and define a persistence unit for the SQL Server datasoure and change hibernate dialect to use Hibernate Spatial. 

persistence.xml
[source, xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<persistence xmlns="https://jakarta.ee/xml/ns/persistence"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="https://jakarta.ee/xml/ns/persistence https://jakarta.ee/xml/ns/persistence/persistence_3_1.xsd"
             version="3.1">

    <persistence-unit name="mssql-jpa-pu" transaction-type="JTA">
        <provider>org.hibernate.jpa.HibernatePersistenceProvider</provider>
        <jta-data-source>java:app/datasources/mssqlDS</jta-data-source>

        <properties>
            <property name="hibernate.dialect" value="org.hibernate.dialect.SQLServerDialect"/>

            <property name="jakarta.persistence.schema-generation.database.action" value="drop-and-create"/>

            <property name="hibernate.jdbc.batch_size" value="50" />

        </properties>
    </persistence-unit>

<!--
    <persistence-unit name="oracle-jpa-user2015-pu" transaction-type="JTA">
        <provider>org.hibernate.jpa.HibernatePersistenceProvider</provider>
        <jta-data-source>java:app/datasources/oracleUser2015DS</jta-data-source>

        <properties>
            <property name="hibernate.dialect" value="org.hibernate.dialect.OracleDialect"/>

            <property name="jakarta.persistence.schema-generation.database.action" value="drop-and-create" />

            <property name="hibernate.jdbc.batch_size" value="50" />

        </properties>
    </persistence-unit>
-->

<!--
    <persistence-unit name="mariadb-jpa-pu" transaction-type="JTA">
        <provider>org.hibernate.jpa.HibernatePersistenceProvider</provider>
        <jta-data-source>java:app/datasources/mariadbDS</jta-data-source>

        <properties>
            <property name="hibernate.dialect" value="org.hibernate.dialect.MariaDBDialect"/>
            <property name="jakarta.persistence.schema-generation.database.action" value="drop-and-create"/>

            <property name="hibernate.jdbc.batch_size" value="50" />
       
        </properties>

    </persistence-unit>
-->

</persistence>
----

[start=8]
. Open the *HelloApplication.java* class and change the @ApplicationPath value from `api` to `restapi`.


== REQUIREMENTS
. Create a new Java class named `EdmontonPropertyAssessmentData` to describe the data in the https://data.edmonton.ca/City-Administration/Property-Assessment-Data-Current-Calendar-Year-/q7d6-ambg[Edmonton Property Assessment Data] csv file

    ---------------------------------------------------------------------
    | EdmontonPropertyAssessmentData                                    |
    |-------------------------------------------------------------------|
    | accountNumber: String                                        		|
    | suite: String                                                     |
    | houseNumber: String                                               |
    | streetName: String                                                |
    | garage: Boolean                                                   |
    | neighbourhoodId: Integer                                          |
    | neighbourhood: String                                             |
    | ward: String                                                      |
    | assessedValue: Long                                               |
    | latitude: double                                                  |
    | longitude: double                                                 |
    | assessmentClass1: String                                          |    
    | pointLocation: org.locationtech.jts.geom.Point                    |    
    | createTime: LocalDateTime                                         |    
    |-------------------------------------------------------------------|
    | EdmontonPropertyAssessmentData()                                  |
    | parseCsv(line: String) : Optional<EdmontonPropertyAssessmentData> |
    ---------------------------------------------------------------------

    .. The `pointLocation` and `createTime` fields can be defined as shown below.
+    
[source, java]
----

    @Column(name = "point_location")
    @jakarta.json.bind.annotation.JsonbTransient
    private org.locationtech.jts.geom.Point pointLocation;

    private LocalDateTime createTime;

    @PrePersist
    private void beforePersist() {
        createTime = LocalDateTime.now();
    }

----
+
    .. Add Jakarta Persistence annotations to identify the class as entity class that is mapped to a database table named `yourNaitUsernameEdmontonPropertyAssessment`.
    .. Add Jakarta Persistence the annotation to specify the `accountNumber` as the primary key attribute.
    .. In the `parseCsv()` method write the code to convert a CSV line to a `EdmontonPropertyAssessmentData` object.
    ... Please beware there is one record in the CSV that does not have values for the columns 
    `neighbourhoodId` (column index 5) , `neighbourhood` (column index 6) and `ward` (column index 7). 
    .... When parsing the csv line assign the null to property if the column value is a blank string.
    ... You can use the following code snippet to convert a well known text for a *POINT* location to a `Point` object.
+    
[source, java]
----

String wktText = tokens[11];
org.locationtech.jts.geom.Point geoLocation = (org.locationtech.jts.geom.Point) new org.locationtech.jts.io.WKTReader().read(wktText);
parsedEdmontonPropertyAssessmentData.setPointLocation(geoLocation);

----
+
. Create a Batch Job with a *batchlet* step to download the Property Assessment Data CSV file from https://data.edmonton.ca/api/views/q7d6-ambg/rows.csv?accessType=DOWNLOAD

. Use the IntelliJ HTTP Client plugin to create an HTTP request to start the batchlet batch job and another HTTP request to check the status of a batch job.

. Use the IntelliJ HTTP Client plugin to execute the HTTP request to start the batchlet batch job.

. Use the IntelliJ HTTP Client plugin to execute the HTTP request to check the job status periodically until the status changes to COMPLETED

. Create a Batch Job with a *chunk* step with an item reader to to read the data from the CSV, an item processor to transform a CSV line to a EdmontonPropertyAssessment object,  an item writer to save the processed EdmontonPropertyAssessment to the database. 
Create a Batch Job Listener to log the time in seconds that the batch job completed in.
During development it is highly recommended that you configure your item reader to read just the first 10 records until you have verify the import process is successful.

. Use the IntelliJ HTTP Client plugin to create an HTTP request to start the chunk batch job.

. Open the *Run* window in IntelliJ IDEA and wait until you see a message from your job listener that the batch job has completed.

. Merge the batchlet and chunk batch job into a single job with two steps. The first step to download the CSV file and a second step to import the CSV data. The `next` attribute of the `<step>` element is used to specify the next step such as  `next=step2`. 

. In the Java package `dmit2015.repository`, create a new Jakarta Persistence respository class for EdmontonPropertyAssessment using the file template for *DMIT2015 Jakarta Persistence Entity Repository* and named it as `EdmontonPropertyAssessmentRepository`.
Add the methods shown below that you can use the find the first 25 property assessment within distanceMeters of a geospatial point 
and a method to return an optional EdmontonPropertyAssessment instance containing the given house number, street name, and suite.
+
[source, java]
----
public List<EdmontonPropertyAssessment> findWithinDistance(
        double longitude,
        double latitude,
        double distanceMeters
) {
    List<EdmontonPropertyAssessment> propertyList = new ArrayList<>();

    var distanceKm = distanceMeters / 1000;
    final double EARTH_MEAN_RADIUS_KM = 6371.0087714;
    final double DEGREES_TO_RADIANS =  Math.PI / 180;
    final double RADIANS_TO_DEGREES =  1 / DEGREES_TO_RADIANS;
    var distanceCentralAngleDegrees = distanceKm * RADIANS_TO_DEGREES / EARTH_MEAN_RADIUS_KM;

    final String jpql = """
        select p
        from EdmontonPropertyAssessmentData p
        where function('st_distance', p.pointLocation, :pointParam) <= :distanceCentralAngleDegreesParam
        """;
    TypedQuery<EdmontonPropertyAssessmentData> query = getEntityManager().createQuery(jpql, EdmontonPropertyAssessmentData.class);

    org.locationtech.jts.geom.Point geoLocation = new GeometryFactory()
            .createPoint(
                    new Coordinate( longitude, latitude  )
            );
    //       Point<G2D> geoLocation = DSL.point(CoordinateReferenceSystems.WGS84, DSL.g(longitude, latitude));

    query.setParameter("pointParam", geoLocation);
    query.setParameter("distanceCentralAngleDegreesParam", distanceCentralAngleDegrees);
    propertyList = query
            .setMaxResults(25)
            .getResultList();

    return propertyList;
}

public Optional<EdmontonPropertyAssessmentData> findByHouseNumberAndStreetNameAndSuite(
        String houseNumber,
        String streetName,
        String suite
) {
    Optional<EdmontonPropertyAssessmentData> optionalSingleResult = Optional.empty();

    try {
        EdmontonPropertyAssessmentData querySingleResult = getEntityManager()
                .createQuery("""
                    select p 
                    from EdmontonPropertyAssessmentData p 
                    where p.houseNumber = :houseNumberParam 
                        and p.streetName = :streetNameParam 
                        and coalesce(p.suite, '') = :suiteParam
                    """, EdmontonPropertyAssessmentData.class)
                .setParameter("houseNumberParam", houseNumber)
                .setParameter("streetNameParam", streetName)
                .setParameter("suiteParam", suite)
                .getSingleResult();
        optionalSingleResult = Optional.of(querySingleResult);
    } catch (Exception ex) {
        ex.printStackTrace();
    }

    return optionalSingleResult;
}

----
+
. In the Java package `dmit2015.resource`, create a new JAX-RS resource class for EdmontonPropertyAssessment using the file template for *DMIT2015 JAX-RS Resource*.
Add the methods shown below that uses the repository methods created in the previous step.
+
[source, java]
----

@GET
@Path("/query/within")
public Response within(
        @QueryParam("longitude") double longitude,
        @QueryParam("latitude") double latitude,
        @QueryParam("distance") double distanceMetre
) {
    List<EdmontonPropertyAssessment> queryResultList = _edmontonPropertyAssessmentRepository
            .findWithinDistance(longitude, latitude, distanceMetre);
    return Response.ok(queryResultList).build();
}

@GET
@Path("/query/byHouseNumberAndStreetNameAndSuite")
public Response findByHouseNumberAndStreetName(
        @QueryParam("houseNumber") String houseNumber,
        @QueryParam("streetName") String streetName,
        @QueryParam("suite") String suite) {
    EdmontonPropertyAssessment querySingleResult = _edmontonPropertyAssessmentRepository
            .findByHouseNumberAndStreetNameAndSuite(houseNumber, streetName, suite)
            .orElseThrow(NotFoundException::new);
    return Response.ok(querySingleResult).build();
}    

@GET 
@Path("count")
public Response countEdmontonPropertyAssessmentData() {
    return Response.ok(_edmontonPropertyAssessmentDataRepository.count()).build();
}

----
+
. Use the IntelliJ HTTP Client plugin to create and execute the HTTP request shown below and verify it returns 8 results.
+
[source]
----
### Get the EdmontonPropertyAssessment by byHouseNumberAndStreetNameAndSuite
GET http://localhost:8080/restapi/EdmontonPropertyAssessmentDatas/query/byHouseNumberAndStreetNameAndSuite?houseNumber=8846&streetName=152B AVENUE NW&suite=

### Get the EdmontonPropertyAssessment by longitude -113.35023446875456, latitude 53.47287377003312, distance 50
GET http://localhost:8080/restapi/EdmontonPropertyAssessmentDatas/query/within?longitude=-113.35023446875456&latitude=53.47287377003312&distance=50

----
+
. Use the IntelliJ HTTP Client plugin to create and execute the HTTP request to get property assessment data for your house/appartment.

. Use the IntelliJ HTTP Client plugin to create and execute the HTTP request to get property assessment data within 50 meters from your house/appartment.

. Create a RESTful service to returns list of the first 100 EdmontonPropertyAssessment matching the given neighbourhood and the assessed value is between the given minimumValue and maximumValue. 
Sort the result by street name then house number.
Use the examples from steps 11-12 as a reference on how you could do this.
You can use the HTTP Client request below to test your RESTful service.
+
[source]
----
### Get the EdmontonPropertyAssessment by byNeighbourhoodAndAssessedValueRange
GET http://localhost:8080/restapi/EdmontonPropertyAssessmentDatas/query/byNeighbourhoodAndAssessedValueRange?neighbourhood=RUTHERFORD&minValue=435000&maxValue=436000
----
. Create a Jakarta Faces page and its associated backing class that can be used to start a batch job for this assignment by clicking on a button and to check the status of a batch job by entering the jobId of a batch job then clicking on a button. 
. Create a Jakarta Faces page to find properties using ONE of the following three queries:
.. Find single property assessment by house number, street name, and suite.
.. Find property assessments by gps location (latitude and longitude) and distance.
.. Find property assessments by neighbourhood, minimum assessed value, and maximum assessed value.
. OPTIONAL CHALLENGE: Deploy your assignment to your OpenShift Developer Sandbox.

== MARKING GUIDE

[cols="4,1"]
|===
|Demonstration Requirement|Mark

| Demonstrate Batch Job with batchlet starts and ends with a status COMPLETED and verification that CSV file has been downloaded.
| 1

| Demonstrate Batch Job with chunk step starts and ends with a status COMPLETED and verification that CSV data has been imported to SQL Server database or Oracle database or MariaDB database.
| 3

| Batch Listener shows in the Console/log window the time in *seconds* that it took to complete batch job. 
| 1

| Demonstrate ONE of the three the HTTP request to find the property assessment data.
| 1

| Demonstrate the Jakarta Faces page to start a batch job and to check the status of a batch job.
| 2

| Demonstrate the Jakarta Faces page to find properties using ONE of the three queries from this assignment.
| 2

|===


== SUBMISSION REQUIREMENTS
* Demonstrate in person or upload a video of the demonstration requirements on or before the due date.
* Commit and push your project to your git repository before the due date.

== Resources
* https://jakarta.ee/specifications/batch/2.0/jakarta-batch-spec-2.0.html[Jakarta Batch]
* https://eclipse-ee4j.github.io/jakartaee-tutorial/#batch-processing[Batch Processing]
* https://www.oracle.com/technical-resources/articles/java/batch-processing-ee-7.html[An Overview of Batch Processing in Java EE 7.0]
* https://docs.jboss.org/hibernate/orm/current/userguide/html_single/Hibernate_User_Guide.html#spatial[Hibernate Spatial]
* https://docs.jboss.org/hibernate/orm/current/userguide/html_single/Hibernate_User_Guide.html#hql[HQL and JPQL]
* https://docs.jboss.org/hibernate/orm/current/userguide/html_single/Hibernate_User_Guide.html#hql-conditional-expressions[JPQL Relational comparison]
